[https://estar987.tistory.com/193](https://estar987.tistory.com/193)

이전의 포스팅한 내용과 이어지는 내용입니다.

## CNI(Container Network Interface)

* CNI는 컨테이너 간의 네트워킹을 제어할 수 있는 Plugin을 만들기 위한 표준
* 다양한 형태의 컨테이너 런타임과 오케스트레이터 사이의 네트워크 계층을 구현하는 방식이 다양하게 분리되어 각자만의 방식으로 발전하게 되는 것을 방지하고 공통된 인터페이스를 제공. K8S는 Pod간의 통신을 위해서 CNI를 사용
* k8s는 기본적으로 kubenet이라는 자체적인 CNI plugin을 제공하지만 네트워크 기능이 매우 제한적임
* 그 단점을 보완하기 위해서 3rd-party Plugin 제공(Flannel, Calico, Weavenet...)

### CNI 필요성

* 각 노드에서 존재하는 container network의 IP 대역이 동일하여 Pod들이 같은 IP를 할당 받을 가능성이 높음
* Pod의 IP가 드르게 할당되었다 하더라도 해당 Pod가 어느 노드에 존재하는지 확인 불가
* 중복되니 않는 IP를 부여해줄 역할을 CNI Plugin 수행

### Kubernetes Cluster init

```
curl -O https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml

kubectl apply -f calico.yaml
```

calico가 올라오면 pending 상태였던 DNS가 작동한다.

```
# k get po -A
NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
kube-system   calico-kube-controllers-658d97c59c-jk6ww   1/1     Running   0          3m1s
kube-system   calico-node-db9hq                          0/1     Running   0          3m1s
kube-system   calico-node-fh2dw                          0/1     Running   0          3m1s
kube-system   calico-node-nqlq4                          0/1     Running   0          3m1s
kube-system   calico-node-spgfh                          0/1     Running   0          3m1s
kube-system   coredns-5dd5756b68-jxs6r                   1/1     Running   0          50m
kube-system   coredns-5dd5756b68-k9hhp                   1/1     Running   0          50m
kube-system   etcd-k8s-master                            1/1     Running   0          51m
kube-system   kube-apiserver-k8s-master                  1/1     Running   0          51m
kube-system   kube-controller-manager-k8s-master         1/1     Running   0          51m
kube-system   kube-proxy-4s2fc                           1/1     Running   0          50m
kube-system   kube-proxy-5xjg2                           1/1     Running   0          26m
kube-system   kube-proxy-bcdpd                           1/1     Running   0          26m
kube-system   kube-proxy-bgrwl                           1/1     Running   0          26m
kube-system   kube-scheduler-k8s-master                  1/1     Running   0          51m
```

Ready 상태로 변경됨

```
# kubectl get no
NAME         STATUS   ROLES           AGE   VERSION
k8s-master   Ready    control-plane   51m   v1.28.12
k8s-node01   Ready    <none>          27m   v1.28.12
k8s-node02   Ready    <none>          27m   v1.28.12
k8s-node03   Ready    <none>          27m   v1.28.12
```